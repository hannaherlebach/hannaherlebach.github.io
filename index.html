<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Hannah Erlebach</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <main>
    <h1>Hannah Erlebach</h1>
    <p>Incoming DPhil in Machine Learning @ Oxford</p>
    <p>London · UK</p>

    <nav>
      <a href="#about">About</a>
      <a href="#research">Research</a>
      <a href="cv.pdf">CV</a>
    </nav>

    <section id="about">
      <h2>About</h2>
      <p>I’m an MSc student in Machine Learning at UCL and will be starting a DPhil at Oxford supervised by Jakob Foerster in October 2025, with full funding from the Cooperative AI PhD Fellowship. My research focuses on the intersection of <strong>AI safety</strong>, <strong>multi-agent systems</strong> and <strong>open-endedness</strong>.<br><br>You can contact me at hannah [dot] erlebach [at] gmail [dot] com.
    </p>
    </section>

    <section id="research">
      <h2>Research</h2>
        <p>I'm currently working on open-ended techniques for automatically red-teaming LLMs. My previous research has focused on cooperation in language models and multi-agent reinforcement learning settings.</p>
      <ul>
        <li><strong>RACCOON: Regret-based Adaptive Curricula for Cooperation</strong>. <strong>Hannah Erlebach</strong> and Jonathan Cook. Published in <i>CoCoMARL workshop at Reinforcement Learning Conference 2024.</i> </li>
        <li><strong>Welfare Diplomacy: Benchmarking Language Model Cooperation</strong>. Gabriel Mukobi, <strong>Hannah Erlebach</strong>, Niklas Lauffer, Lewis Hammond, Alan Chan and Jesse Clifton. Published in <i>SoLaR workshop at NeurIPS 2023.</i> [<a href="https://arxiv.org/abs/2310.08901">arXiv</a>]</li>
      </ul>
    </section>
  </main>
</body>
</html>
